# üß† Formation LangGraph pour l'Agent Analyseur

> **Documentation d'apprentissage pour impl√©menter l'Agent Analyseur du syst√®me de veille**  
> Bas√©e sur l'architecture existante et les mod√®les d√©j√† impl√©ment√©s

## üìã Table des mati√®res

1. [Contexte du projet](#1-contexte-du-projet)
2. [Concepts LangGraph essentiels](#2-concepts-langgraph-essentiels)
3. [Architecture de l'Agent Analyseur](#3-architecture-de-lagent-analyseur)
4. [Mod√®les de donn√©es requis](#4-mod√®les-de-donn√©es-requis)
5. [Impl√©mentation √©tape par √©tape](#5-impl√©mentation-√©tape-par-√©tape)
6. [Int√©gration avec l'existant](#6-int√©gration-avec-lexistant)

---

## 1. Contexte du projet

### üéØ Situation actuelle

Vous avez un **Agent Collecteur** op√©rationnel qui produit des `List[RawContent]` depuis Medium et ArXiv. L'objectif est de cr√©er un **Agent Analyseur** qui transforme ces contenus bruts en articles analys√©s et scor√©s.

### üìä Pipeline cible

```
RawContent[] (Agent Collecteur ‚úÖ) ‚Üí Agent Analyseur üìã ‚Üí ScoredArticle[]
```

### üèóÔ∏è Architecture existante utilis√©e

```python
# D√©j√† impl√©ment√© et fonctionnel
from src.models.database import RawContent
from src.agents.tech_collector_agent import TechCollectorAgent, CollectionConfig

# √Ä cr√©er pour l'Agent Analyseur
from src.models.analysis_models import AnalysisState, ScoredArticle
from src.agents.tech_analyzer_agent import TechAnalyzerAgent
```

---

## 2. Concepts LangGraph essentiels

### üîπ StateGraph - Le workflow central

```python
from langgraph.graph import StateGraph, START, END
from typing import TypedDict, List

# √âtat partag√© entre toutes les √©tapes
class MyWorkflowState(TypedDict):
    input_data: List[str]
    processed_data: List[dict]
    final_result: dict

# Cr√©ation du workflow
workflow = StateGraph(MyWorkflowState)
```

### üîπ N≈ìuds - Fonctions de transformation

```python
def process_step(state: MyWorkflowState) -> MyWorkflowState:
    """Transforme l'√©tat et retourne les modifications."""
    
    # Traitement
    processed = [{"item": item, "status": "processed"} for item in state["input_data"]]
    
    # Retour des modifications d'√©tat
    return {"processed_data": processed}

# Ajout au workflow
workflow.add_node("process", process_step)
```

### üîπ Ar√™tes - Logique de flux

```python
# Ar√™te simple
workflow.add_edge(START, "process")
workflow.add_edge("process", END)

# Ar√™te conditionnelle
def should_continue(state: MyWorkflowState) -> str:
    if len(state["processed_data"]) > 5:
        return "detailed_analysis"
    return "quick_summary"

workflow.add_conditional_edges(
    "process",
    should_continue,
    {"detailed_analysis": "deep_node", "quick_summary": "summary_node"}
)
```

### üîπ Exemple complet minimal

```python
from typing import TypedDict, List
from langgraph.graph import StateGraph, START, END

class SimpleState(TypedDict):
    items: List[str]
    processed_count: int

def add_item(state: SimpleState) -> SimpleState:
    new_item = f"Item {state['processed_count'] + 1}"
    return {
        "items": state["items"] + [new_item],
        "processed_count": state["processed_count"] + 1
    }

def should_continue(state: SimpleState) -> str:
    return "continue" if state["processed_count"] < 3 else "stop"

# Construction
workflow = StateGraph(SimpleState)
workflow.add_node("add_item", add_item)
workflow.add_edge(START, "add_item")
workflow.add_conditional_edges(
    "add_item",
    should_continue,
    {"continue": "add_item", "stop": END}
)

# Compilation et ex√©cution
app = workflow.compile()
result = app.invoke({"items": [], "processed_count": 0})
print(result["items"])  # ['Item 1', 'Item 2', 'Item 3']
```

---

## 3. Architecture de l'Agent Analyseur

### üéØ Objectif sp√©cifique

Transformer `List[RawContent]` (depuis votre Agent Collecteur) en `List[ScoredArticle]` avec analyse intelligente.

### üîÑ Workflow d'analyse

```mermaid
graph TD
    A[RawContent List] --> B[Initialize Analysis]
    B --> C[Filter Relevance]
    C --> D{Is Relevant?}
    D -->|Yes| E[Analyze Technical Depth]
    D -->|No| F[Mark Filtered]
    E --> G[Score Impact]
    G --> H[Prioritize Articles]
    H --> I[Finalize Results]
    F --> I
    I --> J[ScoredArticle List]
```

### üèóÔ∏è Structure de l'agent

```python
class TechAnalyzerAgent:
    """Agent d'analyse bas√© sur LangGraph."""
    
    def __init__(self, expert_profile: dict = None):
        self.expert_profile = expert_profile or DEFAULT_EXPERT_PROFILE
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1)
        self.graph = None
    
    def create_graph(self) -> StateGraph:
        """Cr√©e le workflow d'analyse."""
        workflow = StateGraph(AnalysisState)
        
        # N≈ìuds du processus
        workflow.add_node("initialize", self._initialize_analysis)
        workflow.add_node("filter_relevance", self._filter_relevance)
        workflow.add_node("analyze_technical", self._analyze_technical_depth)
        workflow.add_node("score_articles", self._score_and_rank)
        workflow.add_node("finalize", self._finalize_results)
        
        # Flux
        workflow.add_edge(START, "initialize")
        workflow.add_edge("initialize", "filter_relevance")
        workflow.add_conditional_edges(
            "filter_relevance",
            self._should_analyze_deeper,
            {"analyze": "analyze_technical", "skip": "finalize"}
        )
        workflow.add_edge("analyze_technical", "score_articles")
        workflow.add_edge("score_articles", "finalize")
        workflow.add_edge("finalize", END)
        
        return workflow.compile()
    
    async def analyze_contents(self, raw_contents: List[RawContent]) -> List[ScoredArticle]:
        """Point d'entr√©e principal."""
        # Impl√©mentation avec votre workflow
        pass
```

---

## 4. Mod√®les de donn√©es requis

### üìÑ √âtat du workflow (`AnalysisState`)

```python
# src/models/analysis_models.py

from typing import TypedDict, List, Dict, Any, Optional
from dataclasses import dataclass
from enum import Enum
from datetime import datetime

# R√©utilise vos mod√®les existants
from .database import RawContent

class AnalysisStage(Enum):
    INITIAL = "initial"
    FILTERED = "filtered"
    ANALYZED = "analyzed"
    SCORED = "scored"
    FINALIZED = "finalized"

class AnalysisState(TypedDict):
    """√âtat partag√© du workflow d'analyse."""
    
    # Configuration
    expert_profile: Dict[str, Any]
    
    # Donn√©es d'entr√©e (depuis votre Agent Collecteur)
    raw_contents: List[RawContent]
    
    # √âtat du processus
    current_stage: AnalysisStage
    processed_count: int
    
    # R√©sultats interm√©diaires
    filtered_contents: List[RawContent]
    article_analyses: Dict[str, 'ArticleAnalysis']  # URL -> Analysis
    
    # R√©sultats finaux
    scored_articles: List['ScoredArticle']
    
    # M√©triques
    processing_time: float
    errors: List[str]
```

### üìä Analyse d'article

```python
@dataclass
class ArticleAnalysis:
    """R√©sultat d'analyse d'un article."""
    
    # √âvaluation de base
    is_relevant: bool
    relevance_score: float  # 0-1
    
    # Scores techniques
    technical_depth: float  # 0-1
    innovation_score: float  # 0-1
    practical_value: float  # 0-1
    
    # M√©tadonn√©es
    reasoning: str
    category: str  # "research", "tutorial", "news"
    expertise_level: str  # "beginner", "intermediate", "advanced"
    estimated_read_time: int  # minutes
    
    # Insights IA
    key_insights: List[str]
    strengths: List[str]
    weaknesses: List[str]
```

### üèÜ Article final scor√©

```python
@dataclass
class ScoredArticle:
    """Article final avec analyse compl√®te."""
    
    # Article original (depuis votre collecteur)
    raw_content: RawContent
    
    # Analyse compl√®te
    analysis: ArticleAnalysis
    
    # Scores finaux
    final_score: float  # 0-1
    priority_rank: int
    
    # Enrichissements
    ai_summary: Optional[str] = None
    recommended_for: List[str] = None
    
    # M√©tadonn√©es
    analyzed_at: datetime = None
```

### ‚öôÔ∏è Configuration expert

```python
DEFAULT_EXPERT_PROFILE = {
    "level": "senior",
    "domains": ["machine_learning", "llm", "ai_systems", "software_architecture"],
    "experience_years": 8,
    "avoid_topics": ["beginner_tutorials", "marketing_content", "clickbait"],
    "prefer_topics": ["technical_implementation", "architectural_patterns", 
                      "performance_optimization", "research_insights"],
    "focus_areas": ["scalability", "production_systems", "innovation"]
}
```

---

## 5. Impl√©mentation √©tape par √©tape

### üîπ √âtape 1 : Structure de base

```python
# src/agents/tech_analyzer_agent.py

import asyncio
import time
from typing import List, Dict, Any
from datetime import datetime

from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# Vos mod√®les existants
from ..models.database import RawContent
from ..models.analysis_models import (
    AnalysisState, AnalysisStage, ArticleAnalysis, ScoredArticle,
    DEFAULT_EXPERT_PROFILE
)

class TechAnalyzerAgent:
    """Agent d'analyse technique avec LangGraph."""
    
    def __init__(self, expert_profile: Dict[str, Any] = None):
        self.expert_profile = expert_profile or DEFAULT_EXPERT_PROFILE
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.1)
        self.graph = None
        self._init_prompts()
    
    def _init_prompts(self):
        """Initialise les prompts d'analyse."""
        
        # Prompt de filtrage
        self.relevance_prompt = ChatPromptTemplate.from_messages([
            ("system", """Tu es un expert technique senior. √âvalue si cet article est pertinent pour un profil expert.

PROFIL EXPERT:
- Niveau: {expert_level}
- Domaines: {expert_domains}
- √âviter: {avoid_topics}
- Pr√©f√©rer: {prefer_topics}

R√©ponds par un JSON:
{{
    "is_relevant": true/false,
    "relevance_score": 0.0-1.0,
    "reasoning": "explication",
    "category": "research/tutorial/news",
    "expertise_level": "beginner/intermediate/advanced"
}}"""),
            ("user", """ARTICLE:
Titre: {title}
Source: {source}
Contenu: {content}""")
        ])
        
        # Prompt d'analyse technique
        self.technical_prompt = ChatPromptTemplate.from_messages([
            ("system", """Analyse la profondeur technique de cet article pour un expert.

√âvalue:
- PROFONDEUR TECHNIQUE: Complexit√©, d√©tails d'impl√©mentation
- INNOVATION: Nouveaut√©, originalit√©  
- VALEUR PRATIQUE: Applicabilit√© r√©elle

JSON attendu:
{{
    "technical_depth": 0.0-1.0,
    "innovation_score": 0.0-1.0,
    "practical_value": 0.0-1.0,
    "key_insights": ["insight1", "insight2"],
    "strengths": ["force1"],
    "weaknesses": ["faiblesse1"],
    "reasoning": "analyse d√©taill√©e"
}}"""),
            ("user", """ARTICLE:
Titre: {title}
Contenu: {content}""")
        ])
```

### üîπ √âtape 2 : N≈ìuds du workflow

```python
    # Continuation de TechAnalyzerAgent
    
    def _initialize_analysis(self, state: AnalysisState) -> AnalysisState:
        """Initialise l'analyse."""
        return {
            "current_stage": AnalysisStage.INITIAL,
            "processed_count": 0,
            "filtered_contents": [],
            "article_analyses": {},
            "scored_articles": [],
            "processing_time": time.time(),
            "errors": []
        }
    
    async def _filter_relevance(self, state: AnalysisState) -> AnalysisState:
        """Filtre les articles par pertinence."""
        
        filtered_contents = []
        analyses = {}
        
        for content in state["raw_contents"]:
            try:
                # Analyse avec LLM
                analysis = await self._evaluate_relevance(content)
                analyses[content.url] = analysis
                
                if analysis.is_relevant:
                    filtered_contents.append(content)
                    
            except Exception as e:
                state["errors"].append(f"Erreur filtrage {content.url}: {str(e)}")
        
        return {
            "current_stage": AnalysisStage.FILTERED,
            "filtered_contents": filtered_contents,
            "article_analyses": analyses,
            "processed_count": len(state["raw_contents"])
        }
    
    async def _evaluate_relevance(self, content: RawContent) -> ArticleAnalysis:
        """√âvalue la pertinence avec le LLM."""
        
        # Pr√©paration du prompt avec votre profil expert
        prompt_input = {
            "expert_level": self.expert_profile["level"],
            "expert_domains": ", ".join(self.expert_profile["domains"]),
            "avoid_topics": ", ".join(self.expert_profile["avoid_topics"]),
            "prefer_topics": ", ".join(self.expert_profile["prefer_topics"]),
            "title": content.title,
            "source": content.source,
            "content": content.content[:2000]  # Limite pour le contexte
        }
        
        # Appel LLM
        chain = self.relevance_prompt | self.llm
        response = await chain.ainvoke(prompt_input)
        
        # Parse JSON
        import json
        try:
            result = json.loads(response.content)
            return ArticleAnalysis(
                is_relevant=result["is_relevant"],
                relevance_score=result["relevance_score"],
                technical_depth=0.0,  # √Ä calculer plus tard
                innovation_score=0.0,
                practical_value=0.0,
                reasoning=result["reasoning"],
                category=result["category"],
                expertise_level=result["expertise_level"],
                estimated_read_time=10,  # Estimation par d√©faut
                key_insights=[],
                strengths=[],
                weaknesses=[]
            )
        except (json.JSONDecodeError, KeyError):
            # Fallback s√©curis√©
            return ArticleAnalysis(
                is_relevant=False,
                relevance_score=0.0,
                technical_depth=0.0,
                innovation_score=0.0,
                practical_value=0.0,
                reasoning="Erreur d'analyse",
                category="unknown",
                expertise_level="unknown",
                estimated_read_time=0,
                key_insights=[],
                strengths=[],
                weaknesses=[]
            )
    
    def _should_analyze_deeper(self, state: AnalysisState) -> str:
        """Logique conditionnelle."""
        if len(state["filtered_contents"]) > 0:
            return "analyze"
        return "skip"
    
    async def _analyze_technical_depth(self, state: AnalysisState) -> AnalysisState:
        """Analyse technique approfondie."""
        
        updated_analyses = state["article_analyses"].copy()
        
        for content in state["filtered_contents"]:
            if content.url in updated_analyses:
                try:
                    # Analyse technique avec LLM
                    tech_result = await self._evaluate_technical(content)
                    
                    # Mise √† jour de l'analyse
                    analysis = updated_analyses[content.url]
                    analysis.technical_depth = tech_result["technical_depth"]
                    analysis.innovation_score = tech_result["innovation_score"]
                    analysis.practical_value = tech_result["practical_value"]
                    analysis.key_insights = tech_result["key_insights"]
                    analysis.strengths = tech_result["strengths"]
                    analysis.weaknesses = tech_result["weaknesses"]
                    
                except Exception as e:
                    state["errors"].append(f"Erreur analyse technique {content.url}: {str(e)}")
        
        return {
            "current_stage": AnalysisStage.ANALYZED,
            "article_analyses": updated_analyses
        }
    
    async def _evaluate_technical(self, content: RawContent) -> Dict[str, Any]:
        """√âvaluation technique avec LLM."""
        
        prompt_input = {
            "title": content.title,
            "content": content.content[:3000]
        }
        
        chain = self.technical_prompt | self.llm
        response = await chain.ainvoke(prompt_input)
        
        import json
        try:
            return json.loads(response.content)
        except json.JSONDecodeError:
            return {
                "technical_depth": 0.5,
                "innovation_score": 0.5,
                "practical_value": 0.5,
                "key_insights": [],
                "strengths": [],
                "weaknesses": [],
                "reasoning": "Analyse par d√©faut"
            }
    
    def _score_and_rank(self, state: AnalysisState) -> AnalysisState:
        """Score et classe les articles."""
        
        scored_articles = []
        
        for content in state["filtered_contents"]:
            if content.url in state["article_analyses"]:
                analysis = state["article_analyses"][content.url]
                
                # Calcul score final pond√©r√©
                final_score = (
                    analysis.technical_depth * 0.3 +
                    analysis.innovation_score * 0.25 +
                    analysis.practical_value * 0.25 +
                    analysis.relevance_score * 0.2
                )
                
                scored_article = ScoredArticle(
                    raw_content=content,
                    analysis=analysis,
                    final_score=final_score,
                    priority_rank=0,  # √Ä calculer apr√®s tri
                    analyzed_at=datetime.now()
                )
                
                scored_articles.append(scored_article)
        
        # Tri par score d√©croissant
        scored_articles.sort(key=lambda x: x.final_score, reverse=True)
        
        # Attribution des rangs
        for i, article in enumerate(scored_articles):
            article.priority_rank = i + 1
        
        return {
            "current_stage": AnalysisStage.SCORED,
            "scored_articles": scored_articles
        }
    
    def _finalize_results(self, state: AnalysisState) -> AnalysisState:
        """Finalise l'analyse."""
        
        total_time = time.time() - state["processing_time"]
        
        return {
            "current_stage": AnalysisStage.FINALIZED,
            "processing_time": total_time
        }
```

### üîπ √âtape 3 : Interface principale

```python
    # Point d'entr√©e principal
    async def analyze_contents(
        self, 
        raw_contents: List[RawContent]
    ) -> List[ScoredArticle]:
        """
        Analyse les contenus collect√©s par votre Agent Collecteur.
        
        Args:
            raw_contents: Articles bruts du TechCollectorAgent
            
        Returns:
            Articles analys√©s et scor√©s
        """
        
        # √âtat initial
        initial_state: AnalysisState = {
            "expert_profile": self.expert_profile,
            "raw_contents": raw_contents,
            "current_stage": AnalysisStage.INITIAL,
            "processed_count": 0,
            "filtered_contents": [],
            "article_analyses": {},
            "scored_articles": [],
            "processing_time": 0.0,
            "errors": []
        }
        
        # Cr√©ation et ex√©cution du workflow
        if not self.graph:
            self.graph = self.create_graph()
        
        try:
            final_state = await self.graph.ainvoke(initial_state)
            return final_state["scored_articles"]
            
        except Exception as e:
            raise RuntimeError(f"Erreur workflow d'analyse: {str(e)}")
```

---

## 6. Int√©gration avec l'existant

### üîó Pipeline complet avec votre Agent Collecteur

```python
# Exemple d'utilisation compl√®te avec vos agents existants

async def complete_pipeline():
    """Pipeline complet utilisant vos agents."""
    
    # 1. Collecte avec votre agent existant
    from src.agents import TechCollectorAgent, CollectionConfig
    
    collector = TechCollectorAgent()
    config = CollectionConfig(
        total_limit=15,
        keywords=['AI', 'LLM', 'machine learning'],
        max_age_days=30
    )
    
    collection_result = await collector.collect_all_sources(config)
    print(f"‚úÖ Collect√©: {collection_result.total_filtered} articles")
    
    # 2. Analyse avec le nouvel agent
    analyzer = TechAnalyzerAgent()
    analyzed_articles = await analyzer.analyze_contents(collection_result.contents)
    
    print(f"‚úÖ Analys√©: {len(analyzed_articles)} articles")
    
    # 3. R√©sultats class√©s
    top_articles = analyzed_articles[:3]
    for i, article in enumerate(top_articles, 1):
        print(f"\n{i}. {article.raw_content.title}")
        print(f"   Score: {article.final_score:.2f}")
        print(f"   Cat√©gorie: {article.analysis.category}")
        print(f"   URL: {article.raw_content.url}")
    
    return analyzed_articles

# Ex√©cution
if __name__ == "__main__":
    import asyncio
    asyncio.run(complete_pipeline())
```

### üß™ Tests de base

```python
# tests/test_tech_analyzer_agent.py

import pytest
from unittest.mock import AsyncMock, MagicMock

from src.agents.tech_analyzer_agent import TechAnalyzerAgent
from src.models.database import RawContent

class TestTechAnalyzerAgent:
    
    @pytest.fixture
    def sample_content(self):
        return RawContent(
            title="Advanced Transformer Architectures",
            url="https://example.com/transformers",
            source="arxiv",
            content="This paper presents novel transformer architectures...",
            tags=["transformer", "architecture"]
        )
    
    @pytest.mark.asyncio
    async def test_analyze_contents_basic(self, sample_content):
        """Test d'analyse de base."""
        
        analyzer = TechAnalyzerAgent()
        
        # Mock LLM pour tests rapides
        analyzer.llm = AsyncMock()
        analyzer.llm.ainvoke = AsyncMock(
            return_value=MagicMock(
                content='{"is_relevant": true, "relevance_score": 0.8, "reasoning": "Technical", "category": "research", "expertise_level": "advanced"}'
            )
        )
        
        results = await analyzer.analyze_contents([sample_content])
        
        assert len(results) <= 1
        if results:
            assert results[0].final_score >= 0.0
            assert results[0].analysis.is_relevant
```

### üìä M√©triques d'int√©gration

```python
# Validation avec vos m√©triques existantes
def validate_integration():
    """Valide l'int√©gration avec vos composants."""
    
    # V√©rification compatibilit√© avec TechCollectorAgent
    from src.agents import TechCollectorAgent
    from src.models.database import RawContent
    
    # Test de type compatibility
    collector = TechCollectorAgent()
    analyzer = TechAnalyzerAgent()
    
    # Simulation
    mock_raw_contents = [
        RawContent(title="Test", url="test", source="test", content="test")
    ]
    
    print("‚úÖ Types compatibles avec votre architecture existante")
    print("‚úÖ Pr√™t pour int√©gration dans votre pipeline")
```

---

## üéØ R√©sum√© de l'impl√©mentation

### ‚úÖ Ce que vous obtenez

1. **Agent Analyseur LangGraph** compatible avec votre Agent Collecteur
2. **Workflow structur√©** : Filtrage ‚Üí Analyse ‚Üí Scoring ‚Üí Priorisation  
3. **Int√©gration transparente** avec vos mod√®les `RawContent`
4. **Prompts optimis√©s** pour analyse technique niveau expert
5. **Gestion d'erreurs** robuste et logging d√©taill√©

### üìÅ Fichiers √† cr√©er

```python
# 1. Mod√®les de donn√©es
src/models/analysis_models.py

# 2. Agent principal  
src/agents/tech_analyzer_agent.py

# 3. Tests
tests/test_tech_analyzer_agent.py
```

### üöÄ Pipeline final

```python
# Utilisation compl√®te
async def production_pipeline():
    # Votre collecteur existant
    collector = TechCollectorAgent()
    collection_result = await collector.collect_all_sources(config)
    
    # Nouvel analyseur
    analyzer = TechAnalyzerAgent()
    analyzed_articles = await analyzer.analyze_contents(collection_result.contents)
    
    # Articles pr√™ts pour synth√®se (Phase 4)
    return analyzed_articles[:5]  # Top 5 articles
```

**üéØ Objectif atteint : Transformer votre `List[RawContent]` en `List[ScoredArticle]` avec LangGraph !**
