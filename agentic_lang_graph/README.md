# ğŸ¤– Agent de Veille Intelligente GenAI/LLM

Agent intelligent basÃ© sur **LangGraph** pour automatiser la veille technologique sur l'intelligence artificielle gÃ©nÃ©rative, les LLM et les systÃ¨mes agentic.

## ğŸ¯ Objectif

Produire quotidiennement un digest des **3 articles les plus pertinents** pour un profil expert (Senior Software Engineer), en automatisant :
- ğŸ“¡ **Collecte** multi-sources (Medium, ArXiv)
- ğŸ§  **Analyse** intelligente avec GPT-4o 
- ğŸ“ **SynthÃ¨se** en rapports Markdown

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A[Agent Collecteur] --> B[Agent Analyseur]
    B --> C[Agent SynthÃ©tiseur]
    
    A -.-> D[Medium RSS]
    A -.-> E[ArXiv API]
    
    B -.-> F[GPT-4o Analysis]
    C -.-> G[Markdown Reports]
```

### ğŸ“Š Statut par phase

- âœ… **Phase 1** : Architecture et modÃ¨les de donnÃ©es
- âœ… **Phase 2** : Agent Collecteur Tech (OPÃ‰RATIONNEL)
- â³ **Phase 3** : Agent Analyseur avec LangGraph (EN COURS)
- ğŸ“‹ **Phase 4** : Agent SynthÃ©tiseur

## ğŸš€ Installation rapide

```bash
# Clone et installation
git clone <repo-url>
cd agentic_lang_graph
pip install -r requirements.txt

# Configuration
cp .env.example .env
# Ã‰diter .env avec votre OPENAI_API_KEY

# Test du systÃ¨me
python main.py
```

## ğŸ“Š Utilisation

### Test de collecte rapide
```python
import asyncio
from src.agents import TechCollectorAgent, CollectionConfig

async def test_collecte():
    agent = TechCollectorAgent()
    config = CollectionConfig(
        total_limit=10,
        keywords=['AI', 'LLM', 'machine learning'],
        max_age_days=30
    )
    
    result = await agent.collect_all_sources(config)
    print(f"âœ… {result.total_filtered} articles collectÃ©s")
    
    for article in result.contents[:3]:
        print(f"ğŸ“„ {article.title}")
        print(f"ğŸ”— {article.url}")

asyncio.run(test_collecte())
```

### Collecte complÃ¨te
```python
from src.agents import TechCollectorAgent, CollectionConfig

# Configuration personnalisÃ©e
config = CollectionConfig(
    total_limit=20,
    source_limits={'medium': 10, 'arxiv': 15},
    keywords=[
        'GenAI', 'LLM', 'transformer', 'agent',
        'machine learning', 'neural network'
    ],
    max_age_days=60
)

# Collecte
agent = TechCollectorAgent()
result = await agent.collect_all_sources(config)

print(f"ğŸ“Š Sources: {len(result.sources_stats)}")
print(f"ğŸ“ˆ CollectÃ©s: {result.total_collected}")
print(f"âœ… FiltrÃ©s: {result.total_filtered}")
print(f"â±ï¸ Temps: {result.collection_time:.2f}s")
```

## ğŸ”§ Configuration avancÃ©e

### Sources disponibles
- **Medium** : Flux RSS ciblÃ©s sur IA/ML/GenAI
- **ArXiv** : Papers acadÃ©miques (cs.AI, cs.CL, cs.LG, stat.ML)

### ParamÃ¨tres de collecte
```python
CollectionConfig(
    total_limit=20,              # Limite totale d'articles
    source_limits={              # Limites par source
        'medium': 10,
        'arxiv': 15
    },
    keywords=[                   # Mots-clÃ©s de filtrage
        'AI', 'LLM', 'GenAI'
    ],
    max_age_days=30,            # Articles rÃ©cents uniquement
    expert_level=True           # Filtrage niveau expert
)
```

## ğŸ“ Structure du projet

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                 # Agents LangGraph
â”‚   â”‚   â”œâ”€â”€ tech_collector_agent.py    âœ… OpÃ©rationnel
â”‚   â”‚   â””â”€â”€ tech_analyzer_agent.py     â³ En dÃ©veloppement
â”‚   â”œâ”€â”€ connectors/             # Collecteurs de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ medium_connector.py        âœ… Medium RSS
â”‚   â”‚   â”œâ”€â”€ arxiv_unlimited.py         âœ… ArXiv API
â”‚   â”‚   â””â”€â”€ base_connector.py          âœ… Interface commune
â”‚   â”œâ”€â”€ models/                 # ModÃ¨les de donnÃ©es
â”‚   â””â”€â”€ utils/                  # Configuration et helpers
â”œâ”€â”€ data/                       # Base de donnÃ©es SQLite
â”œâ”€â”€ output/reports/             # Rapports gÃ©nÃ©rÃ©s
â”œâ”€â”€ tests/                      # Tests complets
â””â”€â”€ requirements.txt           # DÃ©pendances
```

## ğŸ§ª Tests

```bash
# Tests complets
python -m pytest tests/ -v

# Tests par catÃ©gorie
python -m pytest tests/ -m "connector"    # Connecteurs
python -m pytest tests/ -m "agent"        # Agents
python -m pytest tests/ -m "unit"         # Tests unitaires

# Tests avec couverture
python -m pytest tests/ --cov=src --cov-report=html
```

## ğŸ¯ Agent Collecteur (Phase 2) âœ… TERMINÃ‰

### FonctionnalitÃ©s
- **Orchestration multi-sources** : Medium + ArXiv en parallÃ¨le
- **DÃ©duplication globale** : Suppression des doublons inter-sources
- **Gestion d'erreurs robuste** : ContinuitÃ© mÃªme si une source Ã©choue
- **Filtrage intelligent** : Par mots-clÃ©s et profil expert
- **MÃ©triques dÃ©taillÃ©es** : Performance et stats par source

### Performance typique
- **Medium** : ~5-8 articles pertinents
- **ArXiv** : ~3-10 papers rÃ©cents
- **Temps** : 1-3 secondes par collecte
- **FiabilitÃ©** : >95% de succÃ¨s

### Configuration des sources

#### Medium
- **Flux RSS** ciblÃ©s : `/tag/artificial-intelligence`, `/tag/machine-learning`
- **Publications** : Towards Data Science, AI Revolution
- **Filtrage** : Contenus niveau intermÃ©diaire Ã  expert

#### ArXiv
- **CatÃ©gories** : cs.AI, cs.CL, cs.LG, cs.CV, stat.ML
- **Recherche** : Mots-clÃ©s dans titres et abstracts
- **PÃ©riode** : Sans restriction (ArxivConnectorUnlimited)
- **MÃ©tadonnÃ©es** : Auteurs, PDF, catÃ©gories, dates

## ğŸ§  Agent Analyseur (Phase 3) â³ EN COURS

### Objectif
Analyser les contenus collectÃ©s avec GPT-4o selon un profil expert pour :
- **Filtrer** les contenus dÃ©butants ou marketing
- **Scorer** par pertinence/impact technique
- **Enrichir** avec mÃ©tadonnÃ©es d'analyse
- **Prioriser** pour la synthÃ¨se finale

### Architecture LangGraph prÃ©vue
```python
workflow = StateGraph(AnalysisState)

# Pipeline d'analyse
workflow.add_node("filter_content", filter_relevance)
workflow.add_node("analyze_technical", analyze_depth)
workflow.add_node("score_impact", calculate_scores)
workflow.add_node("prioritize", rank_articles)

# Logique conditionnelle
workflow.add_conditional_edges(
    "filter_content",
    should_analyze_deeper,
    {"analyze": "analyze_technical", "skip": END}
)
```

## ğŸ“ DÃ©veloppement

### PrÃ©requis
- Python 3.11+
- OpenAI API Key
- 4GB RAM recommandÃ©s

### Variables d'environnement
```env
OPENAI_API_KEY=sk-...                    # Requis
ANALYSIS_MODEL=gpt-4o-mini              # ModÃ¨le d'analyse
SYNTHESIS_MODEL=gpt-4o                  # ModÃ¨le de synthÃ¨se
MAX_ARTICLES_PER_SOURCE=15              # Limite par source
DATABASE_PATH=data/articles.db          # Base de donnÃ©es
```

### Ajout d'une nouvelle source
```python
# 1. HÃ©riter de BaseConnector
class NewSourceConnector(BaseConnector):
    async def collect(self, limit: int) -> List[RawContent]:
        # ImplÃ©mentation spÃ©cifique
        pass
    
    def is_available(self) -> bool:
        # Test de connectivitÃ©
        pass

# 2. Ajouter au TechCollectorAgent
# 3. Tests complets
# 4. Mise Ã  jour configuration
```

## ğŸ” DÃ©pannage

### ProblÃ¨mes courants

**ArXiv ne retourne aucun rÃ©sultat**
```python
# VÃ©rification
from src.connectors import ArxivConnector
arxiv = ArxivConnector()
print(f"Config: {arxiv.days_back} jours")
contents = await arxiv.collect(limit=3)
print(f"RÃ©sultats: {len(contents)}")
```

**Erreurs de timezone**
```python
# Les helpers datetime gÃ¨rent automatiquement
from src.utils.datetime_helpers import get_age_in_days
age = get_age_in_days(article.published_date)  # Toujours sÃ»r
```

**Tests qui Ã©chouent**
```bash
# Tests avec verbose
python -m pytest tests/ -v -s

# Test spÃ©cifique
python -m pytest tests/test_tech_collector_agent.py::test_collect_basic -v
```

## ğŸ“š Ressources

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [OpenAI API](https://platform.openai.com/docs)
- [ArXiv API](https://info.arxiv.org/help/api/index.html)
- [Plan de dÃ©veloppement](./agent_veille_plan.md)

## ğŸ¤ Contribution

Le projet suit une architecture modulaire. Zones de contribution :
- **Connecteurs** : Nouvelles sources de donnÃ©es
- **Agents** : Logique d'analyse et synthÃ¨se
- **ModÃ¨les** : Structures de donnÃ©es
- **Tests** : Couverture et robustesse

## ğŸ“„ License

MIT License - Voir [LICENSE](./LICENSE) pour dÃ©tails.

---

**ğŸš€ Status** : Agent Collecteur opÃ©rationnel, Agent Analyseur en dÃ©veloppement  
**ğŸ“Š Version** : 0.3.0 (Phase 2 terminÃ©e)  
**ğŸ“… DerniÃ¨re MAJ** : 31 mai 2025
