"""
Agent SynthÃ©tiseur Tech avec LangGraph - GÃ©nÃ©rateur de Digest Quotidien.

Cet agent transforme les articles analysÃ©s en digest quotidien structurÃ©
avec rÃ©sumÃ© exÃ©cutif, insights clÃ©s et recommandations actionables.
"""
import asyncio
import json
import time
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from dataclasses import asdict

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, END
from langchain_core.runnables import RunnableConfig
from loguru import logger
from dotenv import load_dotenv
import os

# Chargement automatique des variables d'environnement
load_dotenv()

# Imports des modÃ¨les
from ..agents.tech_analyzer_agent import AnalyzedContent
from ..models.synthesis_models import (
    SynthesisState, SynthesisStage, ReportSection,
    ArticleSynthesis, ActionableRecommendation, TechnicalTrend, DailyDigest,
    DEFAULT_SYNTHESIS_CONFIG, SYNTHESIS_PROMPTS
)


class TechSynthesizerAgent:
    """
    Agent SynthÃ©tiseur Tech avec LangGraph.
    
    Workflow intelligent pour crÃ©er des digests quotidiens Ã  partir
    d'articles analysÃ©s avec :
    - SynthÃ¨se exÃ©cutive automatisÃ©e
    - Extraction d'insights transversaux
    - GÃ©nÃ©ration de recommandations actionables
    - Formatage Markdown professionnel
    """
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        Initialise l'agent synthÃ©tiseur.
        
        Args:
            config: Configuration de synthÃ¨se (utilise la config par dÃ©faut si None)
        """
        self.config = config or DEFAULT_SYNTHESIS_CONFIG.copy()
        self.logger = logger.bind(component="TechSynthesizerAgent")
        
        # Configuration LLM - utilise GPT-4o pour la synthÃ¨se qualitative
        self.llm = ChatOpenAI(
            model="gpt-4o",
            temperature=0.2,  # LÃ©gÃ¨rement plus crÃ©atif pour la synthÃ¨se
            max_tokens=1000,
            api_key=os.getenv('OPENAI_API_KEY')
        )
        
        # Construction du workflow LangGraph
        self.workflow = self._build_workflow()
        self.compiled_workflow = self.workflow.compile()
        
        self.logger.info("ğŸ“ Agent SynthÃ©tiseur Tech (LangGraph) initialisÃ©")
    
    def _build_workflow(self) -> StateGraph:
        """Construit le workflow LangGraph pour la synthÃ¨se."""
        
        # CrÃ©ation du graphe d'Ã©tat
        workflow = StateGraph(SynthesisState)
        
        # Ajout des nÅ“uds
        workflow.add_node("prepare_content", self._prepare_synthesis)
        workflow.add_node("generate_summary", self._generate_executive_summary)
        workflow.add_node("synthesize_articles", self._synthesize_articles)
        workflow.add_node("extract_insights", self._extract_key_insights)
        workflow.add_node("create_recommendations", self._create_recommendations)
        workflow.add_node("format_digest", self._format_markdown_digest)
        workflow.add_node("finalize", self._finalize_synthesis)
        
        # DÃ©finition des arÃªtes - workflow sÃ©quentiel
        workflow.set_entry_point("prepare_content")
        
        workflow.add_edge("prepare_content", "generate_summary")
        workflow.add_edge("generate_summary", "synthesize_articles")
        workflow.add_edge("synthesize_articles", "extract_insights")
        workflow.add_edge("extract_insights", "create_recommendations")
        workflow.add_edge("create_recommendations", "format_digest")
        workflow.add_edge("format_digest", "finalize")
        workflow.add_edge("finalize", END)
        
        return workflow
    
    async def create_daily_digest(
        self, 
        analyzed_articles: List[AnalyzedContent],
        config: Optional[RunnableConfig] = None
    ) -> DailyDigest:
        """
        Point d'entrÃ©e principal pour crÃ©er un digest quotidien.
        
        Args:
            analyzed_articles: Articles analysÃ©s depuis l'Agent Analyseur
            config: Configuration LangGraph optionnelle
            
        Returns:
            Digest quotidien complet avec contenu Markdown
        """
        if not analyzed_articles:
            raise ValueError("Aucun article analysÃ© fourni pour la synthÃ¨se")
        
        self.logger.info(f"ğŸ“ DÃ©but crÃ©ation digest de {len(analyzed_articles)} articles")
        
        # Filtrage des articles recommandÃ©s pour le digest
        recommended_articles = [
            article for article in analyzed_articles 
            if article.analysis.recommended
        ][:self.config["max_articles_in_digest"]]
        
        if not recommended_articles:
            self.logger.warning("Aucun article recommandÃ© trouvÃ©, utilisation des top articles")
            recommended_articles = analyzed_articles[:self.config["max_articles_in_digest"]]
        
        # Ã‰tat initial
        initial_state: SynthesisState = {
            "synthesis_config": self.config,
            "target_audience": self.config["target_audience"],
            "analyzed_articles": recommended_articles,
            "current_stage": SynthesisStage.INITIAL,
            "processed_sections": [],
            "executive_summary": None,
            "articles_synthesis": [],
            "key_insights": [],
            "technical_trends": [],
            "recommendations": [],
            "final_digest": None,
            "generation_time": 0.0,
            "word_count": 0,
            "errors": []
        }
        
        # ExÃ©cution du workflow
        try:
            start_time = time.time()
            final_state = await self.compiled_workflow.ainvoke(
                initial_state,
                config=config or {}
            )
            
            # Extraction du digest final
            digest = final_state.get("final_digest")
            if not digest:
                raise RuntimeError("Ã‰chec de la gÃ©nÃ©ration du digest")
            
            # Calcul du temps de gÃ©nÃ©ration
            generation_time = time.time() - start_time
            digest.generation_time = generation_time
            
            # Logging des rÃ©sultats
            self.logger.info(f"âœ… Digest crÃ©Ã© en {generation_time:.2f}s")
            self.logger.info(f"ğŸ“Š {len(digest.top_articles)} articles, {digest.word_count} mots")
            self.logger.info(f"ğŸ¯ {len(digest.recommendations)} recommandations")
            
            if final_state.get("errors"):
                self.logger.warning(f"âš ï¸ {len(final_state['errors'])} erreurs pendant la gÃ©nÃ©ration")
            
            return digest
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur workflow synthÃ¨se: {e}")
            raise
    
    async def _prepare_synthesis(self, state: SynthesisState) -> SynthesisState:
        """NÅ“ud de prÃ©paration du contenu pour la synthÃ¨se."""
        self.logger.debug("ğŸ”„ PrÃ©paration du contenu pour synthÃ¨se")
        
        # Validation des articles
        articles = state["analyzed_articles"]
        if not articles:
            state["errors"].append("Aucun article Ã  synthÃ©tiser")
            return state
        
        # Tri par score dÃ©croissant pour garantir la qualitÃ©
        sorted_articles = sorted(
            articles, 
            key=lambda x: x.analysis.relevance_score, 
            reverse=True
        )
        
        # Limitation au nombre configurÃ©
        max_articles = state["synthesis_config"]["max_articles_in_digest"]
        final_articles = sorted_articles[:max_articles]
        
        self.logger.info(f"ğŸ“‹ PrÃ©paration: {len(final_articles)} articles sÃ©lectionnÃ©s")
        
        return {
            "current_stage": SynthesisStage.PREPARED,
            "analyzed_articles": final_articles,
            "processed_sections": [ReportSection.TOP_ARTICLES]
        }
    
    async def _generate_executive_summary(self, state: SynthesisState) -> SynthesisState:
        """GÃ©nÃ¨re le rÃ©sumÃ© exÃ©cutif du digest."""
        self.logger.debug("ğŸ“„ GÃ©nÃ©ration rÃ©sumÃ© exÃ©cutif")
        
        articles = state["analyzed_articles"]
        
        # PrÃ©paration du contexte pour le prompt
        articles_overview = "\n".join([
            f"- {article.raw_content.title} (Score: {article.analysis.relevance_score:.2f}, {article.analysis.category})"
            for article in articles
        ])
        
        # Construction du prompt
        prompt_content = SYNTHESIS_PROMPTS["executive_summary"].format(
            target_audience=state["target_audience"],
            articles_count=len(articles),
            articles_overview=articles_overview
        )
        
        try:
            # Appel LLM
            messages = [
                SystemMessage(content="Tu es un expert technique qui rÃ©dige des synthÃ¨ses de veille."),
                HumanMessage(content=prompt_content)
            ]
            
            response = await self.llm.ainvoke(messages)
            executive_summary = response.content.strip()
            
            self.logger.debug(f"âœ… RÃ©sumÃ© exÃ©cutif gÃ©nÃ©rÃ© ({len(executive_summary)} caractÃ¨res)")
            
            return {
                "current_stage": SynthesisStage.SUMMARIZED,
                "executive_summary": executive_summary,
                "processed_sections": state["processed_sections"] + [ReportSection.EXECUTIVE_SUMMARY]
            }
            
        except Exception as e:
            error_msg = f"Erreur gÃ©nÃ©ration rÃ©sumÃ© exÃ©cutif: {str(e)}"
            self.logger.error(error_msg)
            state["errors"].append(error_msg)
            
            # Fallback
            return {
                "executive_summary": "RÃ©sumÃ© exÃ©cutif indisponible (erreur de gÃ©nÃ©ration)",
                "current_stage": SynthesisStage.SUMMARIZED
            }
    
    async def _synthesize_articles(self, state: SynthesisState) -> SynthesisState:
        """SynthÃ©tise chaque article individuellement."""
        self.logger.debug(f"ğŸ“ SynthÃ¨se de {len(state['analyzed_articles'])} articles")
        
        articles_synthesis = []
        
        for article in state["analyzed_articles"]:
            try:
                synthesis = await self._synthesize_single_article(article)
                articles_synthesis.append(synthesis)
                
                self.logger.debug(f"âœ… Article synthÃ©tisÃ©: {synthesis.title_refined[:50]}...")
                
            except Exception as e:
                error_msg = f"Erreur synthÃ¨se article {article.raw_content.title[:30]}...: {str(e)}"
                self.logger.error(error_msg)
                state["errors"].append(error_msg)
                
                # CrÃ©ation d'une synthÃ¨se de fallback
                fallback_synthesis = ArticleSynthesis(
                    original_article=article,
                    title_refined=article.raw_content.title,
                    executive_summary="SynthÃ¨se indisponible (erreur de gÃ©nÃ©ration)",
                    key_takeaways=["Contenu technique Ã  analyser manuellement"],
                    technical_highlights=["DÃ©tails d'implÃ©mentation Ã  examiner"],
                    relevance_for_audience=article.analysis.relevance_score,
                    actionability_score=0.5,
                    innovation_level="unknown",
                    estimated_read_time=10,
                    complexity_level=article.analysis.expertise_level
                )
                articles_synthesis.append(fallback_synthesis)
        
        return {
            "current_stage": SynthesisStage.INSIGHTS_EXTRACTED,
            "articles_synthesis": articles_synthesis
        }
    
    async def _synthesize_single_article(self, article: AnalyzedContent) -> ArticleSynthesis:
        """SynthÃ©tise un article unique avec le LLM."""
        
        # PrÃ©paration du prompt
        prompt_content = SYNTHESIS_PROMPTS["article_synthesis"].format(
            title=article.raw_content.title,
            source=article.raw_content.source,
            category=article.analysis.category,
            score=article.analysis.relevance_score,
            insights=', '.join(article.analysis.key_insights) if article.analysis.key_insights else "N/A",
            content=article.raw_content.content[:2000] if article.raw_content.content else article.raw_content.excerpt or "Contenu non disponible"
        )
        
        messages = [
            SystemMessage(content="Tu es un expert qui synthÃ©tise des articles techniques pour des ingÃ©nieurs seniors."),
            HumanMessage(content=prompt_content)
        ]
        
        response = await self.llm.ainvoke(messages)
        
        # Parse de la rÃ©ponse JSON
        try:
            result_data = json.loads(response.content)
            
            return ArticleSynthesis(
                original_article=article,
                title_refined=result_data.get("title_refined", article.raw_content.title),
                executive_summary=result_data.get("executive_summary", ""),
                key_takeaways=result_data.get("key_takeaways", []),
                technical_highlights=result_data.get("technical_highlights", []),
                relevance_for_audience=article.analysis.relevance_score,
                actionability_score=article.analysis.practical_value,
                innovation_level=result_data.get("innovation_level", "incremental"),
                estimated_read_time=max(5, len(article.raw_content.content or "") // 200),
                complexity_level=result_data.get("complexity_level", article.analysis.expertise_level)
            )
            
        except (json.JSONDecodeError, KeyError) as e:
            self.logger.warning(f"Erreur parsing synthÃ¨se article: {e}")
            # Retourne une synthÃ¨se basique
            return ArticleSynthesis(
                original_article=article,
                title_refined=article.raw_content.title,
                executive_summary=article.analysis.key_insights or "Article technique Ã  analyser",
                key_takeaways=["Contenu technique pertinent"],
                technical_highlights=["ImplÃ©mentation et architecture"],
                relevance_for_audience=article.analysis.relevance_score,
                actionability_score=article.analysis.practical_value,
                innovation_level="incremental",
                estimated_read_time=10,
                complexity_level=article.analysis.expertise_level
            )
    
    async def _extract_key_insights(self, state: SynthesisState) -> SynthesisState:
        """Extrait les insights clÃ©s transversaux."""
        self.logger.debug("ğŸ” Extraction des insights clÃ©s")
        
        # PrÃ©paration du contexte depuis les synthÃ¨ses d'articles
        articles_summaries = "\n\n".join([
            f"ARTICLE: {synthesis.title_refined}\n"
            f"RÃ©sumÃ©: {synthesis.executive_summary}\n"
            f"Points clÃ©s: {', '.join(synthesis.key_takeaways)}\n"
            f"Aspects techniques: {', '.join(synthesis.technical_highlights)}"
            for synthesis in state["articles_synthesis"]
        ])
        
        prompt_content = SYNTHESIS_PROMPTS["insights_extraction"].format(
            articles_summaries=articles_summaries
        )
        
        try:
            messages = [
                SystemMessage(content="Tu es un expert en veille technologique qui identifie les tendances Ã©mergentes."),
                HumanMessage(content=prompt_content)
            ]
            
            response = await self.llm.ainvoke(messages)
            
            # Parse des insights (un par ligne)
            insights_text = response.content.strip()
            insights = [
                insight.strip().lstrip('- ').lstrip('* ') 
                for insight in insights_text.split('\n') 
                if insight.strip() and not insight.strip().startswith('#')
            ]
            
            # Limitation au nombre configurÃ©
            max_insights = state["synthesis_config"]["max_insights"]
            final_insights = insights[:max_insights]
            
            self.logger.debug(f"âœ… {len(final_insights)} insights extraits")
            
            return {
                "current_stage": SynthesisStage.INSIGHTS_EXTRACTED,
                "key_insights": final_insights,
                "processed_sections": state["processed_sections"] + [ReportSection.KEY_INSIGHTS]
            }
            
        except Exception as e:
            error_msg = f"Erreur extraction insights: {str(e)}"
            self.logger.error(error_msg)
            state["errors"].append(error_msg)
            
            # Fallback
            return {
                "key_insights": ["Analyse des tendances indisponible"],
                "current_stage": SynthesisStage.INSIGHTS_EXTRACTED
            }
    
    async def _create_recommendations(self, state: SynthesisState) -> SynthesisState:
        """CrÃ©e les recommandations actionables."""
        self.logger.debug("ğŸ¯ CrÃ©ation des recommandations actionables")
        
        # PrÃ©paration du contexte avec articles et insights
        content_summary = f"""ARTICLES SYNTHÃ‰TISÃ‰S:
{chr(10).join([f"- {s.title_refined}: {s.executive_summary}" for s in state["articles_synthesis"]])}

INSIGHTS CLÃ‰S:
{chr(10).join([f"- {insight}" for insight in state["key_insights"]])}"""
        
        prompt_content = SYNTHESIS_PROMPTS["recommendations"].format(
            content_summary=content_summary,
            target_audience=state["target_audience"]
        )
        
        try:
            messages = [
                SystemMessage(content="Tu es un tech lead qui transforme la veille en actions concrÃ¨tes."),
                HumanMessage(content=prompt_content)
            ]
            
            response = await self.llm.ainvoke(messages)
            
            # Parse des recommandations JSON
            result_data = json.loads(response.content)
            recommendations_data = result_data.get("recommendations", [])
            
            recommendations = []
            for rec_data in recommendations_data:
                recommendation = ActionableRecommendation(
                    title=rec_data.get("title", "Recommandation"),
                    description=rec_data.get("description", ""),
                    action_items=rec_data.get("action_items", []),
                    based_on_articles=[article.raw_content.url for article in state["analyzed_articles"]],
                    category=rec_data.get("category", "investigation"),
                    priority=rec_data.get("priority", "medium"),
                    time_investment=rec_data.get("time_investment", "1-4h"),
                    complexity="intermediate",
                    suggested_next_steps=[],
                    related_technologies=[]
                )
                recommendations.append(recommendation)
            
            # Limitation au nombre configurÃ©
            max_recommendations = state["synthesis_config"]["max_recommendations"]
            final_recommendations = recommendations[:max_recommendations]
            
            self.logger.debug(f"âœ… {len(final_recommendations)} recommandations crÃ©Ã©es")
            
            return {
                "current_stage": SynthesisStage.RECOMMENDATIONS_CREATED,
                "recommendations": final_recommendations,
                "processed_sections": state["processed_sections"] + [ReportSection.RECOMMENDATIONS]
            }
            
        except (json.JSONDecodeError, KeyError, Exception) as e:
            error_msg = f"Erreur crÃ©ation recommandations: {str(e)}"
            self.logger.error(error_msg)
            state["errors"].append(error_msg)
            
            # Fallback avec recommandations basiques
            fallback_recommendation = ActionableRecommendation(
                title="Approfondir les technologies Ã©mergentes",
                description="Explorer les innovations identifiÃ©es dans la veille",
                action_items=["Lire les articles sÃ©lectionnÃ©s", "Ã‰valuer l'impact sur vos projets"],
                based_on_articles=[],
                category="learning",
                priority="medium",
                time_investment="1-4h",
                complexity="intermediate",
                suggested_next_steps=[],
                related_technologies=[]
            )
            
            return {
                "recommendations": [fallback_recommendation],
                "current_stage": SynthesisStage.RECOMMENDATIONS_CREATED
            }
    
    async def _format_markdown_digest(self, state: SynthesisState) -> SynthesisState:
        """Formate le digest final en Markdown."""
        self.logger.debug("ğŸ“‹ Formatage du digest Markdown")
        
        try:
            # Construction du digest final
            digest = DailyDigest(
                date=datetime.now(),
                title=f"Tech Digest - {datetime.now().strftime('%d %B %Y')}",
                subtitle="Veille technologique GenAI/LLM/Agentic pour ingÃ©nieurs seniors",
                target_audience=state["target_audience"],
                executive_summary=state["executive_summary"] or "RÃ©sumÃ© non disponible",
                top_articles=state["articles_synthesis"],
                key_insights=state["key_insights"],
                technical_trends=[],  # SimplifiÃ© pour cette version
                recommendations=state["recommendations"],
                total_articles_analyzed=len(state["analyzed_articles"]),
                articles_recommended=len([a for a in state["analyzed_articles"] if a.analysis.recommended]),
                average_quality_score=sum(a.analysis.relevance_score for a in state["analyzed_articles"]) / len(state["analyzed_articles"]),
                all_article_links=[
                    {"title": a.raw_content.title, "url": a.raw_content.url, "source": a.raw_content.source}
                    for a in state["analyzed_articles"]
                ],
                suggested_reading=[],
                generated_at=datetime.now(),
                generator_version="1.0",
                llm_model_used="gpt-4o"
            )
            
            # GÃ©nÃ©ration du contenu Markdown
            markdown_content = self._generate_markdown_content(digest)
            digest.markdown_content = markdown_content
            digest.word_count = len(markdown_content.split())
            digest.estimated_read_time = max(1, digest.word_count // 200)  # 200 mots/minute
            
            self.logger.debug(f"âœ… Digest formatÃ© ({digest.word_count} mots, {digest.estimated_read_time}min)")
            
            return {
                "current_stage": SynthesisStage.FORMATTED,
                "final_digest": digest,
                "word_count": digest.word_count,
                "processed_sections": state["processed_sections"] + [ReportSection.RESOURCES]
            }
            
        except Exception as e:
            error_msg = f"Erreur formatage digest: {str(e)}"
            self.logger.error(error_msg)
            state["errors"].append(error_msg)
            
            # Digest minimal de fallback
            fallback_digest = DailyDigest(
                date=datetime.now(),
                title="Tech Digest - Erreur de gÃ©nÃ©ration",
                subtitle="Erreur lors de la gÃ©nÃ©ration du digest",
                target_audience=state["target_audience"],
                executive_summary="Erreur de gÃ©nÃ©ration du digest",
                top_articles=[],
                key_insights=[],
                technical_trends=[],
                recommendations=[],
                total_articles_analyzed=0,
                articles_recommended=0,
                average_quality_score=0.0,
                all_article_links=[],
                suggested_reading=[],
                markdown_content="# Erreur\n\nÃ‰chec de la gÃ©nÃ©ration du digest.",
                word_count=0,
                estimated_read_time=0
            )
            
            return {
                "final_digest": fallback_digest,
                "current_stage": SynthesisStage.FORMATTED
            }
    
    def _generate_markdown_content(self, digest: DailyDigest) -> str:
        """GÃ©nÃ¨re le contenu Markdown du digest."""
        
        # En-tÃªte
        markdown = f"""# {digest.title}

> {digest.subtitle}  
> ğŸ“… {digest.date.strftime('%d %B %Y')} â€¢ ğŸ¯ {digest.target_audience} â€¢ â±ï¸ {digest.estimated_read_time} min de lecture

---

## ğŸ“Š RÃ©sumÃ© ExÃ©cutif

{digest.executive_summary}

**ğŸ“ˆ MÃ©triques de veille:**
- ğŸ“„ **Articles analysÃ©s:** {digest.total_articles_analyzed}
- âœ… **Articles recommandÃ©s:** {digest.articles_recommended}
- ğŸ¯ **Score moyen de qualitÃ©:** {digest.average_quality_score:.2f}/1.0

---

## ğŸ† Top Articles

"""
        
        # Articles
        for i, article in enumerate(digest.top_articles, 1):
            innovation_emoji = {"breakthrough": "ğŸš€", "significant": "ğŸ’¡", "incremental": "ğŸ“ˆ"}.get(article.innovation_level, "ğŸ“„")
            complexity_emoji = {"expert": "ğŸ”¬", "advanced": "ğŸ§ ", "intermediate": "ğŸ“š"}.get(article.complexity_level, "ğŸ“–")
            
            markdown += f"""### {i}. {innovation_emoji} {article.title_refined}

**{complexity_emoji} {article.complexity_level.title()} â€¢ â±ï¸ {article.estimated_read_time}min â€¢ ğŸ“Š {article.relevance_for_audience:.2f}/1.0**

{article.executive_summary}

**ğŸ”‘ Points clÃ©s:**
"""
            for takeaway in article.key_takeaways:
                markdown += f"- {takeaway}\n"
            
            if article.technical_highlights:
                markdown += "\n**âš™ï¸ Aspects techniques:**\n"
                for highlight in article.technical_highlights:
                    markdown += f"- {highlight}\n"
            
            markdown += f"\nğŸ”— **Source:** [{article.original_article.raw_content.source}]({article.original_article.raw_content.url})\n\n---\n\n"
        
        # Insights
        if digest.key_insights:
            markdown += "## ğŸ’¡ Insights ClÃ©s\n\n"
            for insight in digest.key_insights:
                markdown += f"- **{insight}**\n"
            markdown += "\n---\n\n"
        
        # Recommandations
        if digest.recommendations:
            markdown += "## ğŸ¯ Recommandations Actionables\n\n"
            for i, rec in enumerate(digest.recommendations, 1):
                priority_emoji = {"high": "ğŸ”¥", "medium": "âš¡", "low": "ğŸ“Œ"}.get(rec.priority, "ğŸ“‹")
                category_emoji = {"learning": "ğŸ“š", "implementation": "âš™ï¸", "investigation": "ğŸ”", "monitoring": "ğŸ‘€"}.get(rec.category, "ğŸ“‹")
                
                markdown += f"""### {i}. {priority_emoji} {rec.title}

**{category_emoji} {rec.category.title()} â€¢ â±ï¸ {rec.time_investment} â€¢ ğŸ¯ {rec.priority.title()} priority**

{rec.description}

**Actions concrÃ¨tes:**
"""
                for action in rec.action_items:
                    markdown += f"- [ ] {action}\n"
                
                markdown += "\n---\n\n"
        
        # Ressources
        markdown += "## ğŸ“š Ressources\n\n"
        markdown += "### ğŸ”— Liens des articles\n\n"
        for link in digest.all_article_links:
            markdown += f"- [{link['title']}]({link['url']}) *({link['source']})*\n"
        
        # Footer
        markdown += f"""

---

*Digest gÃ©nÃ©rÃ© le {digest.generated_at.strftime('%d/%m/%Y Ã  %H:%M')} par {digest.generator_version} â€¢ LLM: {digest.llm_model_used}*
"""
        
        return markdown
    
    async def _finalize_synthesis(self, state: SynthesisState) -> SynthesisState:
        """Finalise la synthÃ¨se."""
        self.logger.debug("âœ… Finalisation de la synthÃ¨se")
        
        return {
            "current_stage": SynthesisStage.FINALIZED,
            "generation_time": time.time()
        }
    
    async def save_digest_to_file(self, digest: DailyDigest, output_dir: str = "output/reports") -> str:
        """Sauvegarde le digest dans un fichier Markdown."""
        
        # CrÃ©ation du rÃ©pertoire de sortie
        os.makedirs(output_dir, exist_ok=True)
        
        # Nom du fichier avec date
        filename = f"tech_digest_{digest.date.strftime('%Y%m%d')}.md"
        filepath = os.path.join(output_dir, filename)
        
        # Ã‰criture du fichier
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(digest.markdown_content)
        
        self.logger.info(f"ğŸ“ Digest sauvegardÃ©: {filepath}")
        return filepath
