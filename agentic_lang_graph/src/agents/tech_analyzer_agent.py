"""
Agent Analyse Tech avec LangGraph - Version Production.

Transformation du prototype simple en workflow LangGraph structur√©
avec parall√©lisation, gestion d'√©tat et patterns avanc√©s.
"""
import asyncio
import json
import os
from typing import List, Dict, Optional, Any, Annotated
from dataclasses import dataclass, field
from datetime import datetime

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.runnables import RunnableConfig
from loguru import logger
from dotenv import load_dotenv

# Chargement automatique des variables d'environnement
load_dotenv()

# Imports des mod√®les centralis√©s
from ..connectors import RawContent
from ..models.analysis_models import (
    ExpertProfile,
    ContentAnalysis,
    AnalyzedContent,
    DifficultyLevel
)
from ..utils.prompt_loader import load_prompt


@dataclass
class AnalysisState:
    """√âtat du workflow d'analyse LangGraph."""
    
    # Input
    raw_contents: List[RawContent] = field(default_factory=list)
    expert_profile: Optional[ExpertProfile] = None
    
    # Processing state
    current_batch: List[RawContent] = field(default_factory=list)
    analysis_results: List[AnalyzedContent] = field(default_factory=list)
    failed_analyses: List[Dict[str, Any]] = field(default_factory=list)
    
    # Configuration
    batch_size: int = 3  # Nombre de contenus analys√©s en parall√®le
    max_retries: int = 2
    
    # Metadata
    total_contents: int = 0
    processed_count: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    
    # Messages pour debugging
    messages: Annotated[list, add_messages] = field(default_factory=list)


class TechAnalyzerAgent:
    """
    Agent Analyse Tech avec LangGraph - Version Production.
    
    Workflow intelligent pour analyser les contenus collect√©s avec :
    - Parall√©lisation des analyses LLM
    - Gestion d'√©tat centralis√©e  
    - Retry et fallback automatiques
    - Monitoring et debugging avanc√©s
    """
    
    def __init__(self, expert_profile: ExpertProfile = None):
        """
        Initialise l'agent analyseur avec LangGraph.
        
        Args:
            expert_profile: Profil de l'expert pour personnaliser l'analyse
        """
        self.profile = expert_profile or ExpertProfile()
        self.logger = logger.bind(component="TechAnalyzerAgent")
        
        # Configuration LLM
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.1,
            max_tokens=500,
            api_key=os.getenv('OPENAI_API_KEY')
        )
        
        # Construction du workflow LangGraph
        self.workflow = self._build_workflow()
        self.compiled_workflow = self.workflow.compile()
        
        self.logger.info("üîÑ Agent Analyse Tech (LangGraph) initialis√©")
    
    def _build_workflow(self) -> StateGraph:
        """Construit le workflow LangGraph pour l'analyse."""
        
        # Cr√©ation du graphe d'√©tat
        workflow = StateGraph(AnalysisState)
        
        # Ajout des n≈ìuds
        workflow.add_node("initialize", self._initialize_analysis)
        workflow.add_node("batch_processor", self._process_batch)
        workflow.add_node("single_analyzer", self._analyze_single_content)
        workflow.add_node("aggregator", self._aggregate_results)
        workflow.add_node("finalizer", self._finalize_analysis)
        
        # D√©finition des ar√™tes
        workflow.set_entry_point("initialize")
        
        workflow.add_edge("initialize", "batch_processor")
        workflow.add_edge("batch_processor", "single_analyzer")
        workflow.add_edge("single_analyzer", "aggregator")
        
        # Condition pour continuer ou finaliser
        workflow.add_conditional_edges(
            "aggregator",
            self._should_continue,
            {
                "continue": "batch_processor",
                "finish": "finalizer"
            }
        )
        
        workflow.add_edge("finalizer", END)
        
        return workflow
    
    async def analyze_contents(self, 
                             raw_contents: List[RawContent],
                             config: Optional[RunnableConfig] = None) -> List[AnalyzedContent]:
        """
        Point d'entr√©e principal pour analyser des contenus.
        
        Args:
            raw_contents: Contenus bruts √† analyser
            config: Configuration LangGraph optionnelle
            
        Returns:
            Liste des contenus analys√©s et enrichis
        """
        if not raw_contents:
            return []
        
        self.logger.info(f"üß† D√©but analyse LangGraph de {len(raw_contents)} contenus")
        
        # √âtat initial
        initial_state = AnalysisState(
            raw_contents=raw_contents,
            expert_profile=self.profile,
            total_contents=len(raw_contents),
            start_time=datetime.now()
        )
        
        # Ex√©cution du workflow
        try:
            final_state = await self.compiled_workflow.ainvoke(
                initial_state,
                config=config or {}
            )
            
            # Extraction des r√©sultats
            analyzed_contents = final_state.get("analysis_results", [])
            
            # Les r√©sultats sont d√©j√† tri√©s par final_score dans _finalize_analysis
            
            # Logging des r√©sultats
            processing_time = (final_state.get("end_time", datetime.now()) - 
                             final_state.get("start_time", datetime.now())).total_seconds()
            
            self.logger.info(f"‚úÖ Analyse termin√©e en {processing_time:.2f}s")
            self.logger.info(f"üìä {len(analyzed_contents)} contenus analys√©s")
            
            if final_state.get("failed_analyses"):
                self.logger.warning(f"‚ö†Ô∏è {len(final_state['failed_analyses'])} analyses √©chou√©es")
            
            return analyzed_contents
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur workflow LangGraph: {e}")
            raise
    
    async def _initialize_analysis(self, state: AnalysisState) -> AnalysisState:
        """N≈ìud d'initialisation du workflow."""
        self.logger.debug("üîÑ Initialisation analyse")
        
        state.messages.append(HumanMessage(
            content=f"Initialisation analyse de {state.total_contents} contenus"
        ))
        
        state.processed_count = 0
        state.start_time = datetime.now()
        
        return state
    
    async def _process_batch(self, state: AnalysisState) -> AnalysisState:
        """Pr√©pare le prochain batch de contenus √† analyser."""
        
        # Calcul du batch suivant
        start_idx = state.processed_count
        end_idx = min(start_idx + state.batch_size, state.total_contents)
        
        if start_idx >= state.total_contents:
            # Plus de contenus √† traiter
            state.current_batch = []
            return state
        
        state.current_batch = state.raw_contents[start_idx:end_idx]
        
        self.logger.debug(f"üì¶ Batch {start_idx}-{end_idx}: {len(state.current_batch)} contenus")
        
        return state
    
    async def _analyze_single_content(self, state: AnalysisState) -> AnalysisState:
        """Analyse un batch de contenus en parall√®le."""
        
        if not state.current_batch:
            return state
        
        self.logger.debug(f"üß† Analyse parall√®le de {len(state.current_batch)} contenus")
        
        # Analyse en parall√®le avec asyncio.gather
        analysis_tasks = [
            self._analyze_content_with_llm(content, state.expert_profile)
            for content in state.current_batch
        ]
        
        try:
            # Ex√©cution parall√®le avec gestion des erreurs
            analysis_results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
            
            # Traitement des r√©sultats
            for i, result in enumerate(analysis_results):
                content = state.current_batch[i]
                
                if isinstance(result, Exception):
                    # Gestion d'erreur
                    self.logger.error(f"‚ùå Erreur analyse {content.title[:30]}...: {result}")
                    state.failed_analyses.append({
                        "content": content,
                        "error": str(result),
                        "timestamp": datetime.now()
                    })
                else:
                    # Succ√®s
                    analyzed_content = AnalyzedContent(
                        raw_content=content,
                        analysis=result
                    )
                    
                    # Calcul du score final pond√©r√© pour compatibilit√© avec le synth√©tiseur
                    final_score = (
                        result.relevance_score * 0.4 +  # Normalisation 0-10 -> 0-1
                        result.practical_value * 0.3 +
                        (8.0 if result.recommended else 4.0) * 0.3
                    ) / 10.0  # Normalisation finale vers 0-1
                    
                    # Ajout de l'attribut final_score pour compatibilit√©
                    analyzed_content.final_score = final_score
                    analyzed_content.priority_rank = 0  # Sera calcul√© plus tard
                    
                    state.analysis_results.append(analyzed_content)
                    
                    score = result.relevance_score
                    status = "‚úÖ" if result.recommended else "‚ùå"
                    self.logger.debug(f"{status} {score:.1f}/10 - {content.title[:50]}...")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur batch analysis: {e}")
            # Marquer tout le batch comme √©chou√©
            for content in state.current_batch:
                state.failed_analyses.append({
                    "content": content,
                    "error": str(e),
                    "timestamp": datetime.now()
                })
        
        return state
    
    async def _analyze_content_with_llm(self, 
                                      content: RawContent, 
                                      profile: ExpertProfile) -> ContentAnalysis:
        """Analyse un contenu unique avec le LLM."""
        
        # Construction des messages
        system_prompt = self._build_system_prompt(profile)
        analysis_prompt = self._build_analysis_prompt(content)
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=analysis_prompt)
        ]
        
        # Appel LLM
        response = await self.llm.ainvoke(messages)
        
        # Parse de la r√©ponse JSON
        try:
            result_data = json.loads(response.content)
            
            return ContentAnalysis(
                relevance_score=float(result_data.get("relevance_score", 0)),
                difficulty_level=DifficultyLevel(result_data.get("difficulty_level", "intermediate")),
                main_topics=result_data.get("main_topics", []),
                key_insights=result_data.get("key_insights", ""),
                practical_value=float(result_data.get("practical_value", 0)),
                reasons=result_data.get("reasons", []),
                recommended=bool(result_data.get("recommended", False))
            )
            
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            self.logger.error(f"Erreur parsing r√©ponse LLM: {e}")
            # Retourne une analyse par d√©faut
            return ContentAnalysis(
                relevance_score=5.0,
                difficulty_level=DifficultyLevel.INTERMEDIATE,
                main_topics=["parsing_error"],
                key_insights="Erreur d'analyse automatique",
                practical_value=5.0,
                reasons=["Erreur de parsing JSON"],
                recommended=False
            )
    
    async def _aggregate_results(self, state: AnalysisState) -> AnalysisState:
        """Agr√®ge les r√©sultats du batch actuel."""
        
        # Mise √† jour du compteur
        state.processed_count += len(state.current_batch)
        
        # Logging de progression
        progress = (state.processed_count / state.total_contents) * 100
        self.logger.info(f"üìà Progression: {state.processed_count}/{state.total_contents} ({progress:.1f}%)")
        
        # Clear du batch actuel
        state.current_batch = []
        
        return state
    
    def _should_continue(self, state: AnalysisState) -> str:
        """D√©termine si le workflow doit continuer ou se terminer."""
        
        if state.processed_count >= state.total_contents:
            return "finish"
        else:
            return "continue"
    
    async def _finalize_analysis(self, state: AnalysisState) -> AnalysisState:
        """Finalise l'analyse et calcule les statistiques."""
        
        state.end_time = datetime.now()
        
        # Tri des r√©sultats par final_score et attribution des rangs
        if state.analysis_results:
            sorted_results = sorted(
                state.analysis_results, 
                key=lambda x: x.final_score, 
                reverse=True
            )
            
            # Attribution des rangs de priorit√©
            for i, result in enumerate(sorted_results, 1):
                result.priority_rank = i
            
            # Remplacement de la liste par la version tri√©e
            state.analysis_results = sorted_results
        
        # Statistiques finales
        total_analyzed = len(state.analysis_results)
        total_failed = len(state.failed_analyses)
        success_rate = (total_analyzed / state.total_contents) * 100 if state.total_contents > 0 else 0
        
        self.logger.info(f"üìä Analyse termin√©e:")
        self.logger.info(f"   ‚úÖ R√©ussies: {total_analyzed}")
        self.logger.info(f"   ‚ùå √âchou√©es: {total_failed}")
        self.logger.info(f"   üìà Taux de succ√®s: {success_rate:.1f}%")
        
        # Recommandations
        recommended_count = sum(1 for result in state.analysis_results if result.analysis.recommended)
        self.logger.info(f"   üéØ Recommandations: {recommended_count}/{total_analyzed}")
        
        # Log des top scores
        if state.analysis_results:
            avg_score = sum(r.final_score for r in state.analysis_results) / len(state.analysis_results)
            self.logger.info(f"   üìà Score final moyen: {avg_score:.2f}")
        
        return state
    
    def _build_system_prompt(self, profile: ExpertProfile) -> str:
        """Construit le prompt syst√®me pour le LLM."""
        return load_prompt("analyzer/system", {
            "expert_level": profile.level.value,
            "interests": ', '.join(profile.interests),
            "avoid_topics": ', '.join(profile.avoid_topics),
            "preferred_content_types": ', '.join(profile.preferred_content_types)
        })

    def _build_analysis_prompt(self, content: RawContent) -> str:
        """Construit le prompt d'analyse pour un contenu sp√©cifique."""
        
        info_parts = [
            f"TITRE: {content.title}",
            f"SOURCE: {content.source}",
            f"URL: {content.url}"
        ]
        
        if content.excerpt:
            info_parts.append(f"R√âSUM√â: {content.excerpt}")
        
        if content.author:
            info_parts.append(f"AUTEUR: {content.author}")
        
        if content.tags:
            info_parts.append(f"TAGS: {', '.join(content.tags)}")
        
        if content.published_date:
            info_parts.append(f"DATE: {content.published_date.strftime('%Y-%m-%d')}")
        
        return load_prompt("analyzer/content_analysis", {
            "article_info": chr(10).join(info_parts),
            "expert_level": self.profile.level.value
        })
    
    async def get_recommendations(self, 
                                raw_contents: List[RawContent], 
                                limit: int = 5) -> List[AnalyzedContent]:
        """
        Retourne les top recommandations apr√®s analyse avec LangGraph.
        
        Args:
            raw_contents: Contenus √† analyser
            limit: Nombre max de recommandations
            
        Returns:
            Top contenus recommand√©s tri√©s par score
        """
        analyzed = await self.analyze_contents(raw_contents)
        
        # Filtre uniquement les recommand√©s et applique la limite
        recommended = [c for c in analyzed if c.analysis.recommended][:limit]
        
        self.logger.info(f"üéØ {len(recommended)} recommandations sur {len(analyzed)} analys√©s")
        return recommended
    
    def print_workflow_state(self, state: AnalysisState):
        """Affiche l'√©tat du workflow (pour debug)."""
        print(f"\nüìä √âTAT WORKFLOW LANGGRAPH")
        print(f"Total contenus: {state.total_contents}")
        print(f"Trait√©s: {state.processed_count}")
        print(f"Analys√©s: {len(state.analysis_results)}")
        print(f"√âchecs: {len(state.failed_analyses)}")
        print(f"Batch actuel: {len(state.current_batch)}")
